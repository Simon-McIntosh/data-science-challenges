{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b1f050",
   "metadata": {},
   "source": [
    "# Plasma Volume Dataset Preparation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates using the FAIR-MAST API to download and prepare datasets for the Data Science Challenges. The download process accommodates the large file sizes of Plasma Volume and Equilibrium challenge files that exceed standard git repository limits. These steps showcase common data preparation techniques for real-world machine learning projects.\n",
    "\n",
    "By studying the API commands alongside the [FAIR-MAST](https://mastapp.site/) documentation, you can extend these examples to build better inference engines and explore MAST data to create your own tools.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook will:\n",
    "1. Demonstrate FAIR-MAST data access methods\n",
    "2. Download datasets for the Plasma Volume and Equilibrium challenges\n",
    "3. Process data through interpolation, formatting, and concatenation\n",
    "4. Provide a foundation for building custom inference tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69cd89",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This section offers utility functions for accessing the FAIR-MAST object store. Our machine learning tools require data with specific dimensions:\n",
    "\n",
    "- **Signals**: Shape (n, ...) where n represents time points (samples)\n",
    "- **Targets**: Shape (n, m) where n represents time points (samples) and m represents output features\n",
    "\n",
    "The preprocessing workflow addresses these key challenges with MAST data:\n",
    "\n",
    "1. **Time Base Standardization**: Interpolates data from different sampling rates onto one common time base\n",
    "2. **Dimension Ordering**: Transposes data so time always appears as the first dimension (n)\n",
    "3. **Data Concatenation**: Merges data from multiple shots and diagnostics into a unified dataset while preserving metadata\n",
    "\n",
    "These preprocessing steps create well-structured datasets ready for machine learning model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba2049",
   "metadata": {},
   "source": [
    "## Dataset Preparation for Plasma Volume Challenge\n",
    "\n",
    "The Plasma Volume challenge requires predicting the volume of a plasma from a single camera frame. This section outlines the complete dataset preparation pipeline, from data acquisition to the creation of train/test splits.\n",
    "\n",
    "### Preparation Steps\n",
    "\n",
    "1. **Data Source**: The dataset uses camera frames from the M9 campaign captured at the precise moment of maximum plasma volume for each shot.\n",
    "\n",
    "2. **Data Extraction**: For each shot, we extract:\n",
    "   - Camera frames from the MAST database\n",
    "   - Corresponding plasma volume measurements\n",
    "   - Timing information to align frames with maximum volume events\n",
    "\n",
    "3. **Dataset Organization**: \n",
    "   - Images are grouped by their resolution (640x448 resolution selected for the challenge)\n",
    "   - Training/test split uses a 70/30 ratio with a fixed random seed (7) for reproducibility\n",
    "   - Test set plasma volume values are saved separately as ground truth\n",
    "\n",
    "4. **Data Storage**: \n",
    "   - Uses NetCDF format for efficient storage of multi-dimensional data\n",
    "   - Implements caching with pickle files to avoid repeated expensive data retrieval\n",
    "\n",
    "These steps create a standardized dataset that enables consistent evaluation across different machine learning approaches.\n",
    "\n",
    "### Camera Data Processing\n",
    "\n",
    "These functions retrieve and process camera data for the Plasma Volume Data Science Challenge. Downloading the complete dataset requires approximately 20 minutes with a fast internet connection. The code implements a caching strategy that stores processed data locally, eliminating the need to repeat this time-consuming download process.\n",
    "\n",
    "### How the Camera Data Processing Scripts Work\n",
    "\n",
    "1. **Data Collection**: The `build_camera_data()` function accesses M9 campaign shots and extracts camera frames at the moment of maximum plasma volume.\n",
    "\n",
    "2. **Efficient Caching**: The `load_camera_data()` function uses pickle files as a local cache to avoid rebuilding this computationally expensive dataset.\n",
    "\n",
    "3. **Challenge Dataset Creation**: The code pairs extracted camera frames with their plasma volume values to create a supervised learning dataset.\n",
    "\n",
    "### Data Processing Flow\n",
    "\n",
    "1. The code fetches the moment of maximum plasma volume for each shot from MAST metadata\n",
    "2. It retrieves the camera frame nearest to that exact moment\n",
    "3. Each frame links to its corresponding plasma volume measurement\n",
    "4. Frames organize by resolution/dimension\n",
    "5. The data splits into training and test sets for the challenge\n",
    "\n",
    "This preprocessing workflow handles the computational demands of accessing numerous M9 campaign shots and extracting precisely timed frames from maximum volume events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "from importlib import resources\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dask(shot: int, group: str, level: int = 2) -> xr.Dataset:\n",
    "    \"\"\"Return a Dataset from the MAST Zarr store.\"\"\"\n",
    "    return xr.open_zarr(\n",
    "        f\"https://s3.echo.stfc.ac.uk/mast/level{level}/shots/{shot}.zarr\",\n",
    "        group=group,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_camera_data():\n",
    "    \"\"\"\n",
    "    Retrieve camera frames from shots in the M9 campaign at the moment of maximum plasma volume.\n",
    "    \n",
    "    Returns a dictionary of camera datasets organized by image dimensions, containing frames\n",
    "    captured at the time of maximum plasma volume for each shot in the campaign.\n",
    "    \"\"\"\n",
    "    URL = \"https://mastapp.site\"\n",
    "    summary = pd.read_parquet(f'{URL}/parquet/level2/shots?filters=campaign$eq:M9')\n",
    "    summary = summary.loc[:, [\"shot_id\", \"campaign\", \"cpf_tvol_max\", \"cpf_vol_max\"]]\n",
    "    summary = summary.dropna(subset=\"cpf_tvol_max\")\n",
    "\n",
    "    dataset = {}\n",
    "    for _, (shot_id, time_vol_max, vol_max) in tqdm.tqdm(\n",
    "        summary.loc[:, [\"shot_id\", \"cpf_tvol_max\", \"cpf_vol_max\"]].iterrows(), \n",
    "        desc=\"Loading camera data\",\n",
    "        total=summary.shape[0]\n",
    "        ):\n",
    "\n",
    "        try:\n",
    "            frames = to_dask(int(shot_id), \"rbb\", level=1)\n",
    "            frame = frames.sel(time=time_vol_max, method=\"nearest\")\n",
    "            frame.load()\n",
    "            frame.coords[\"shot_id\"] = shot_id\n",
    "            frame.coords[\"volume\"] = vol_max\n",
    "\n",
    "            key = tuple(frame.shape[1:])\n",
    "            try:\n",
    "                dataset[key].append(frame)\n",
    "            except KeyError:\n",
    "                dataset[key] = [frame]\n",
    "        except (IndexError, KeyError):  # no camera data\n",
    "            pass\n",
    "\n",
    "    # concatenate datasets\n",
    "    camera_data = {}\n",
    "    for key, objs in dataset.items():\n",
    "        camera_data[key] = xr.concat(objs, \"shot_id\", combine_attrs=\"drop_conflicts\")\n",
    "        camera_data[key] = camera_data[key].rename({\"data\": \"frame\"})\n",
    "        del camera_data[key].attrs[\"mds_name\"]\n",
    "        del camera_data[key].attrs[\"CLASS\"]\n",
    "\n",
    "    return camera_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_camera_data():\n",
    "    \"\"\"Return camera data, try to load from cache else build.\"\"\"\n",
    "    path = pathlib.Path().absolute().parent / \"fair_mast_data/plasma_volume\"\n",
    "    filename = path / \"camera_data.pkl\"\n",
    "    try:\n",
    "        with open(filename, \"rb\") as f:\n",
    "            camera_data = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        camera_data = build_camera_data()\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(camera_data, f)\n",
    "    return camera_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e24d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_data = load_camera_data()\n",
    "\n",
    "# plot image size histogram\n",
    "sizes = [data.sizes[\"shot_id\"] for data in camera_data.values()]\n",
    "plt.bar([str(key) for key in camera_data], sizes)\n",
    "plt.xlabel('image size')\n",
    "plt.ylabel('image number')\n",
    "plt.xticks(rotation=90)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d43e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3  # fraction of dataset to use for testing\n",
    "dataset = load_camera_data()[(448, 640)]\n",
    "dataset = dataset.drop_vars([\"time\", \"shot_id\"])  # anonymize dataset \n",
    "\n",
    "# shuffle dataset\n",
    "shot_index = np.arange(dataset.sizes[\"shot_id\"], dtype=int)\n",
    "rng = np.random.default_rng(7)\n",
    "rng.shuffle(shot_index)\n",
    "test_split = int(np.floor(test_size * dataset.sizes[\"shot_id\"]))\n",
    "\n",
    "train = dataset.isel(shot_id=shot_index[test_split:])\n",
    "test = dataset.isel(shot_id=shot_index[:test_split])\n",
    "solution = test.volume.to_pandas().to_frame()\n",
    "rng.random(len(solution))\n",
    "solution[\"Usage\"] = np.where(rng.random(len(solution)) < 0.5, \"Public\", \"Private\")\n",
    "\n",
    "test = test.drop_vars(\"volume\")  # drop target from test dataset\n",
    "\n",
    "# write datasets to file\n",
    "pkg_path = resources.files(\"data_science_challenges\")\n",
    "data_path = pkg_path / \"fair_mast_data\" / \"plasma_volume\"\n",
    "train.to_netcdf(data_path / \"train.nc\")\n",
    "test.to_netcdf(data_path / \"test.nc\")\n",
    "solution.to_csv(data_path / \"solution.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_challenges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
